{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, BatchNormalization\n",
    "from keras.layers import Conv1D, UpSampling1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import ReLU\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from optuna) (20.4)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from optuna) (1.5.0)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from optuna) (1.20.3)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.8.0-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from optuna) (1.3.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from optuna) (4.47.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from alembic->optuna) (2.8.1)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: PyYAML>=3.12 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from cliff->optuna) (5.3.1)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.0.1-py3-none-any.whl (139 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Collecting pyreadline3; sys_platform == \"win32\" and python_version >= \"3.8\"\n",
      "  Downloading pyreadline3-3.3-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (19.3.0)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\srovi\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=28cb679143f24cdb50153b3937bd768bca5c22bf8be339b18b2008dee8c34af9\n",
      "  Stored in directory: c:\\users\\srovi\\appdata\\local\\pip\\cache\\wheels\\7f\\1a\\65\\84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: python-editor, Mako, alembic, cmaes, pbr, pyreadline3, pyperclip, cmd2, stevedore, PrettyTable, cliff, colorlog, optuna\n",
      "Successfully installed Mako-1.1.4 PrettyTable-2.1.0 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.0.1 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 pyreadline3-3.3 python-editor-1.0.4 stevedore-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('subj_merged.pkl')\n",
    "df.columns\n",
    "#feat_list = [ 'ecg', 'emg', 'c_eda', 'c_temp', 'resp', 'bvp', 'w_eda', 'w_temp']\n",
    "#feat_list = [ 'ecg', 'emg', 'c_eda', 'c_temp', 'resp']\n",
    "feat_list = ['bvp', 'w_eda', 'w_temp']\n",
    "df = df[df[\"c_temp\"]>0]\n",
    "df = df[df[\"label\"].isin([1,2,3])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df[\"sid\"].unique().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(n_input_dim, n_out_dim, num_hidden1, num_hidden2, drop_rate, weight_decay):\n",
    "    \n",
    "    # Define network\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(num_hidden1, input_dim=n_input_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
    "    model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "    model.add(tf.keras.layers.Dense(num_hidden2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
    "    model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "    model.add(tf.keras.layers.Dense(n_out_dim, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert class labels to one hot encoding array\n",
    "def one_hot_enc(r, k):\n",
    "    new_r = np.zeros((r.shape[0],k))\n",
    "    for i, val in enumerate(r):\n",
    "        new_r[i, val-1] = 1\n",
    "    \n",
    "    return new_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):   \n",
    "    # leave one out method\n",
    "    test_metrics = []\n",
    "    \n",
    "    # tuning parameters\n",
    "    num_hidden1 = trial.suggest_int(\"n_units_l0\", 8, 10, log=True)\n",
    "    num_hidden2 = trial.suggest_int(\"n_units_l1\", 4, 8, log=True)\n",
    "    drop_rate=trial.suggest_float(\"rate\", 0.2, 0.4)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-8, 1e-5, log=True)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    #momentum = trial.suggest_float(\"momentum\", 1e-5, 1e-2, log=True)\n",
    "    b=trial.suggest_int(\"batch_size\", 32, 128)\n",
    "    ep=trial.suggest_int(\"epoch\", 5, 15)\n",
    "        \n",
    "    for sid in ids:\n",
    "        df_train = df[df[\"sid\"] != sid]\n",
    "        df_test = df[df[\"sid\"] == sid]\n",
    "        x_scaled_train = StandardScaler().fit_transform(df_train[feat_list])\n",
    "        x_scaled_test = StandardScaler().fit_transform(df_test[feat_list])\n",
    "        x_train = x_scaled_train\n",
    "        x_test = x_scaled_test\n",
    "        y_train = df_train[\"label\"].values.astype(int)\n",
    "        y_test = df_test[\"label\"].values.astype(int)\n",
    "        K = len(df_train[\"label\"].unique())\n",
    "        y_train1 = one_hot_enc(y_train, K)\n",
    "        y_test1 = one_hot_enc(y_test, K)\n",
    "        n_input_dim = x_train.shape[1]\n",
    "        \n",
    "\n",
    "        model = ANN_model(n_input_dim, K, num_hidden1, num_hidden2, drop_rate, weight_decay)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(lr==lr), metrics=['accuracy'])\n",
    "        hist = model.fit(x_train, y_train1, epochs=ep, batch_size=b, verbose=False, validation_data = (x_test, y_test1))\n",
    "\n",
    "\n",
    "        results = model.evaluate(x_test, y_test1)\n",
    "        print(\"Test subject: \", sid)\n",
    "        print(\"Test Loss: %.3f\\nTest Accuracy: %.3f\" %(results[0], results[1]))\n",
    "        test_metrics.append((results[0], results[1]))\n",
    "        \n",
    "    l = np.array(test_metrics)\n",
    "    score = l[:,1].mean()\n",
    "    \n",
    "    print(\"len(test_metrics) :\", len(test_metrics))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:11:33,646]\u001b[0m A new study created in memory with name: no-name-33ef9036-a7cc-4f80-98d3-cacc246ba472\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 794us/step - loss: 0.3355 - accuracy: 0.9626\n",
      "Test subject:  2\n",
      "Test Loss: 0.336\n",
      "Test Accuracy: 0.963\n",
      "270/270 [==============================] - 0s 837us/step - loss: 3.9498 - accuracy: 0.6055\n",
      "Test subject:  3\n",
      "Test Loss: 3.950\n",
      "Test Accuracy: 0.606\n",
      "271/271 [==============================] - 0s 730us/step - loss: 0.4787 - accuracy: 0.8270\n",
      "Test subject:  4\n",
      "Test Loss: 0.479\n",
      "Test Accuracy: 0.827\n",
      "278/278 [==============================] - 0s 757us/step - loss: 0.3949 - accuracy: 0.7896\n",
      "Test subject:  5\n",
      "Test Loss: 0.395\n",
      "Test Accuracy: 0.790\n",
      "276/276 [==============================] - 0s 764us/step - loss: 0.9611 - accuracy: 0.5811\n",
      "Test subject:  6\n",
      "Test Loss: 0.961\n",
      "Test Accuracy: 0.581\n",
      "275/275 [==============================] - 0s 764us/step - loss: 0.4960 - accuracy: 0.8308\n",
      "Test subject:  7\n",
      "Test Loss: 0.496\n",
      "Test Accuracy: 0.831\n",
      "277/277 [==============================] - 0s 755us/step - loss: 0.3551 - accuracy: 0.8091\n",
      "Test subject:  8\n",
      "Test Loss: 0.355\n",
      "Test Accuracy: 0.809\n",
      "275/275 [==============================] - 0s 874us/step - loss: 1.0705 - accuracy: 0.8028\n",
      "Test subject:  9\n",
      "Test Loss: 1.070\n",
      "Test Accuracy: 0.803\n",
      "285/285 [==============================] - 0s 697us/step - loss: 0.6226 - accuracy: 0.7903\n",
      "Test subject:  10\n",
      "Test Loss: 0.623\n",
      "Test Accuracy: 0.790\n",
      "279/279 [==============================] - 0s 752us/step - loss: 0.6353 - accuracy: 0.6898\n",
      "Test subject:  11\n",
      "Test Loss: 0.635\n",
      "Test Accuracy: 0.690\n",
      "279/279 [==============================] - 0s 915us/step - loss: 0.5400 - accuracy: 0.8169\n",
      "Test subject:  13\n",
      "Test Loss: 0.540\n",
      "Test Accuracy: 0.817\n",
      "279/279 [==============================] - 0s 714us/step - loss: 1.1233 - accuracy: 0.5122\n",
      "Test subject:  14\n",
      "Test Loss: 1.123\n",
      "Test Accuracy: 0.512\n",
      "280/280 [==============================] - 0s 761us/step - loss: 0.5199 - accuracy: 0.8073\n",
      "Test subject:  15\n",
      "Test Loss: 0.520\n",
      "Test Accuracy: 0.807\n",
      "278/278 [==============================] - 0s 742us/step - loss: 1.1514 - accuracy: 0.6840\n",
      "Test subject:  16\n",
      "Test Loss: 1.151\n",
      "Test Accuracy: 0.684\n",
      "285/285 [==============================] - 0s 692us/step - loss: 0.8936 - accuracy: 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:13:57,244]\u001b[0m Trial 0 finished with value: 0.7454176266988118 and parameters: {'n_units_l0': 9, 'n_units_l1': 5, 'rate': 0.2943432983556913, 'weight_decay': 3.4540499483808e-07, 'lr': 9.336504220253229e-05, 'batch_size': 112, 'epoch': 9}. Best is trial 0 with value: 0.7454176266988118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.894\n",
      "Test Accuracy: 0.672\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 781us/step - loss: 0.7724 - accuracy: 0.8180\n",
      "Test subject:  2\n",
      "Test Loss: 0.772\n",
      "Test Accuracy: 0.818\n",
      "270/270 [==============================] - 0s 717us/step - loss: 1.1165 - accuracy: 0.6128\n",
      "Test subject:  3\n",
      "Test Loss: 1.117\n",
      "Test Accuracy: 0.613\n",
      "271/271 [==============================] - 0s 756us/step - loss: 0.6263 - accuracy: 0.8276\n",
      "Test subject:  4\n",
      "Test Loss: 0.626\n",
      "Test Accuracy: 0.828\n",
      "278/278 [==============================] - 0s 861us/step - loss: 0.6019 - accuracy: 0.7223\n",
      "Test subject:  5\n",
      "Test Loss: 0.602\n",
      "Test Accuracy: 0.722\n",
      "276/276 [==============================] - 0s 736us/step - loss: 1.0707 - accuracy: 0.6515\n",
      "Test subject:  6\n",
      "Test Loss: 1.071\n",
      "Test Accuracy: 0.651\n",
      "275/275 [==============================] - 0s 694us/step - loss: 0.9934 - accuracy: 0.5396\n",
      "Test subject:  7\n",
      "Test Loss: 0.993\n",
      "Test Accuracy: 0.540\n",
      "277/277 [==============================] - 0s 695us/step - loss: 0.5838 - accuracy: 0.8189\n",
      "Test subject:  8\n",
      "Test Loss: 0.584\n",
      "Test Accuracy: 0.819\n",
      "275/275 [==============================] - 0s 708us/step - loss: 0.4298 - accuracy: 0.9628\n",
      "Test subject:  9\n",
      "Test Loss: 0.430\n",
      "Test Accuracy: 0.963\n",
      "285/285 [==============================] - 0s 754us/step - loss: 0.7182 - accuracy: 0.8174\n",
      "Test subject:  10\n",
      "Test Loss: 0.718\n",
      "Test Accuracy: 0.817\n",
      "279/279 [==============================] - 0s 1ms/step - loss: 0.7827 - accuracy: 0.6746\n",
      "Test subject:  11\n",
      "Test Loss: 0.783\n",
      "Test Accuracy: 0.675\n",
      "279/279 [==============================] - 0s 819us/step - loss: 0.5799 - accuracy: 0.8254\n",
      "Test subject:  13\n",
      "Test Loss: 0.580\n",
      "Test Accuracy: 0.825\n",
      "279/279 [==============================] - 0s 665us/step - loss: 0.7714 - accuracy: 0.6235\n",
      "Test subject:  14\n",
      "Test Loss: 0.771\n",
      "Test Accuracy: 0.623\n",
      "280/280 [==============================] - 0s 729us/step - loss: 0.5804 - accuracy: 0.8138\n",
      "Test subject:  15\n",
      "Test Loss: 0.580\n",
      "Test Accuracy: 0.814\n",
      "278/278 [==============================] - 0s 837us/step - loss: 1.0369 - accuracy: 0.7940\n",
      "Test subject:  16\n",
      "Test Loss: 1.037\n",
      "Test Accuracy: 0.794\n",
      "285/285 [==============================] - 0s 742us/step - loss: 0.7306 - accuracy: 0.8366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:18:30,098]\u001b[0m Trial 1 finished with value: 0.7559124191602071 and parameters: {'n_units_l0': 10, 'n_units_l1': 4, 'rate': 0.3965785646017962, 'weight_decay': 3.811170549640512e-07, 'lr': 0.0012784350171365813, 'batch_size': 59, 'epoch': 10}. Best is trial 1 with value: 0.7559124191602071.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.731\n",
      "Test Accuracy: 0.837\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 885us/step - loss: 0.3788 - accuracy: 0.8865\n",
      "Test subject:  2\n",
      "Test Loss: 0.379\n",
      "Test Accuracy: 0.886\n",
      "270/270 [==============================] - 0s 703us/step - loss: 1.6199 - accuracy: 0.6965\n",
      "Test subject:  3\n",
      "Test Loss: 1.620\n",
      "Test Accuracy: 0.696\n",
      "271/271 [==============================] - 0s 716us/step - loss: 0.4968 - accuracy: 0.8282\n",
      "Test subject:  4\n",
      "Test Loss: 0.497\n",
      "Test Accuracy: 0.828\n",
      "278/278 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.7560\n",
      "Test subject:  5\n",
      "Test Loss: 0.365\n",
      "Test Accuracy: 0.756\n",
      "276/276 [==============================] - 0s 709us/step - loss: 1.0290 - accuracy: 0.6037\n",
      "Test subject:  6\n",
      "Test Loss: 1.029\n",
      "Test Accuracy: 0.604\n",
      "275/275 [==============================] - 0s 708us/step - loss: 0.6407 - accuracy: 0.6550\n",
      "Test subject:  7\n",
      "Test Loss: 0.641\n",
      "Test Accuracy: 0.655\n",
      "277/277 [==============================] - 0s 700us/step - loss: 0.8667 - accuracy: 0.7926\n",
      "Test subject:  8\n",
      "Test Loss: 0.867\n",
      "Test Accuracy: 0.793\n",
      "275/275 [==============================] - 0s 771us/step - loss: 1.2666 - accuracy: 0.8044\n",
      "Test subject:  9\n",
      "Test Loss: 1.267\n",
      "Test Accuracy: 0.804\n",
      "285/285 [==============================] - 0s 801us/step - loss: 1.2531 - accuracy: 0.6958\n",
      "Test subject:  10\n",
      "Test Loss: 1.253\n",
      "Test Accuracy: 0.696\n",
      "279/279 [==============================] - 0s 711us/step - loss: 0.4250 - accuracy: 0.9389\n",
      "Test subject:  11\n",
      "Test Loss: 0.425\n",
      "Test Accuracy: 0.939\n",
      "279/279 [==============================] - 0s 730us/step - loss: 0.7729 - accuracy: 0.7120\n",
      "Test subject:  13\n",
      "Test Loss: 0.773\n",
      "Test Accuracy: 0.712\n",
      "279/279 [==============================] - 0s 704us/step - loss: 1.7438 - accuracy: 0.4692\n",
      "Test subject:  14\n",
      "Test Loss: 1.744\n",
      "Test Accuracy: 0.469\n",
      "280/280 [==============================] - 0s 749us/step - loss: 0.6931 - accuracy: 0.8077\n",
      "Test subject:  15\n",
      "Test Loss: 0.693\n",
      "Test Accuracy: 0.808\n",
      "278/278 [==============================] - 0s 702us/step - loss: 1.7659 - accuracy: 0.7115\n",
      "Test subject:  16\n",
      "Test Loss: 1.766\n",
      "Test Accuracy: 0.712\n",
      "285/285 [==============================] - 0s 699us/step - loss: 0.6703 - accuracy: 0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:21:38,828]\u001b[0m Trial 2 finished with value: 0.7457404772440592 and parameters: {'n_units_l0': 8, 'n_units_l1': 5, 'rate': 0.28510470162119084, 'weight_decay': 8.484516471976209e-07, 'lr': 0.0012379054265605185, 'batch_size': 125, 'epoch': 13}. Best is trial 1 with value: 0.7559124191602071.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.670\n",
      "Test Accuracy: 0.828\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 701us/step - loss: 0.3746 - accuracy: 0.8050\n",
      "Test subject:  2\n",
      "Test Loss: 0.375\n",
      "Test Accuracy: 0.805\n",
      "270/270 [==============================] - 0s 681us/step - loss: 2.1585 - accuracy: 0.7782\n",
      "Test subject:  3\n",
      "Test Loss: 2.158\n",
      "Test Accuracy: 0.778\n",
      "271/271 [==============================] - 0s 703us/step - loss: 0.4959 - accuracy: 0.8278\n",
      "Test subject:  4\n",
      "Test Loss: 0.496\n",
      "Test Accuracy: 0.828\n",
      "278/278 [==============================] - 0s 718us/step - loss: 0.6978 - accuracy: 0.7338\n",
      "Test subject:  5\n",
      "Test Loss: 0.698\n",
      "Test Accuracy: 0.734\n",
      "276/276 [==============================] - 0s 690us/step - loss: 1.5897 - accuracy: 0.7120\n",
      "Test subject:  6\n",
      "Test Loss: 1.590\n",
      "Test Accuracy: 0.712\n",
      "275/275 [==============================] - 0s 910us/step - loss: 0.5718 - accuracy: 0.8308\n",
      "Test subject:  7\n",
      "Test Loss: 0.572\n",
      "Test Accuracy: 0.831\n",
      "277/277 [==============================] - 0s 727us/step - loss: 0.3028 - accuracy: 0.8377\n",
      "Test subject:  8\n",
      "Test Loss: 0.303\n",
      "Test Accuracy: 0.838\n",
      "275/275 [==============================] - 0s 693us/step - loss: 0.8645 - accuracy: 0.7429\n",
      "Test subject:  9\n",
      "Test Loss: 0.865\n",
      "Test Accuracy: 0.743\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.5561 - accuracy: 0.7936\n",
      "Test subject:  10\n",
      "Test Loss: 0.556\n",
      "Test Accuracy: 0.794\n",
      "279/279 [==============================] - 0s 880us/step - loss: 0.8718 - accuracy: 0.8340\n",
      "Test subject:  11\n",
      "Test Loss: 0.872\n",
      "Test Accuracy: 0.834\n",
      "279/279 [==============================] - 0s 698us/step - loss: 0.6042 - accuracy: 0.8269\n",
      "Test subject:  13\n",
      "Test Loss: 0.604\n",
      "Test Accuracy: 0.827\n",
      "279/279 [==============================] - 0s 708us/step - loss: 1.6132 - accuracy: 0.4451\n",
      "Test subject:  14\n",
      "Test Loss: 1.613\n",
      "Test Accuracy: 0.445\n",
      "280/280 [==============================] - 0s 728us/step - loss: 0.5238 - accuracy: 0.8150\n",
      "Test subject:  15\n",
      "Test Loss: 0.524\n",
      "Test Accuracy: 0.815\n",
      "278/278 [==============================] - 0s 698us/step - loss: 0.9623 - accuracy: 0.6750\n",
      "Test subject:  16\n",
      "Test Loss: 0.962\n",
      "Test Accuracy: 0.675\n",
      "285/285 [==============================] - 0s 703us/step - loss: 0.6283 - accuracy: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:23:22,686]\u001b[0m Trial 3 finished with value: 0.7658190627892812 and parameters: {'n_units_l0': 10, 'n_units_l1': 4, 'rate': 0.20530457665009125, 'weight_decay': 3.6879689342548564e-07, 'lr': 0.0017712960898782209, 'batch_size': 92, 'epoch': 5}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.628\n",
      "Test Accuracy: 0.829\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 712us/step - loss: 0.7227 - accuracy: 0.8050\n",
      "Test subject:  2\n",
      "Test Loss: 0.723\n",
      "Test Accuracy: 0.805\n",
      "270/270 [==============================] - 0s 725us/step - loss: 1.6692 - accuracy: 0.7319\n",
      "Test subject:  3\n",
      "Test Loss: 1.669\n",
      "Test Accuracy: 0.732\n",
      "271/271 [==============================] - 0s 852us/step - loss: 0.4586 - accuracy: 0.8282\n",
      "Test subject:  4\n",
      "Test Loss: 0.459\n",
      "Test Accuracy: 0.828\n",
      "278/278 [==============================] - 0s 760us/step - loss: 0.4546 - accuracy: 0.7649\n",
      "Test subject:  5\n",
      "Test Loss: 0.455\n",
      "Test Accuracy: 0.765\n",
      "276/276 [==============================] - 0s 790us/step - loss: 1.1230 - accuracy: 0.7615\n",
      "Test subject:  6\n",
      "Test Loss: 1.123\n",
      "Test Accuracy: 0.761\n",
      "275/275 [==============================] - 0s 752us/step - loss: 0.5792 - accuracy: 0.7232\n",
      "Test subject:  7\n",
      "Test Loss: 0.579\n",
      "Test Accuracy: 0.723\n",
      "277/277 [==============================] - 0s 748us/step - loss: 0.8087 - accuracy: 0.7163\n",
      "Test subject:  8\n",
      "Test Loss: 0.809\n",
      "Test Accuracy: 0.716\n",
      "275/275 [==============================] - 0s 808us/step - loss: 0.2932 - accuracy: 0.9721\n",
      "Test subject:  9\n",
      "Test Loss: 0.293\n",
      "Test Accuracy: 0.972\n",
      "285/285 [==============================] - 0s 719us/step - loss: 0.8141 - accuracy: 0.7902\n",
      "Test subject:  10\n",
      "Test Loss: 0.814\n",
      "Test Accuracy: 0.790\n",
      "279/279 [==============================] - 0s 726us/step - loss: 0.5755 - accuracy: 0.7999\n",
      "Test subject:  11\n",
      "Test Loss: 0.576\n",
      "Test Accuracy: 0.800\n",
      "279/279 [==============================] - 0s 814us/step - loss: 0.6841 - accuracy: 0.6575\n",
      "Test subject:  13\n",
      "Test Loss: 0.684\n",
      "Test Accuracy: 0.657\n",
      "279/279 [==============================] - 0s 700us/step - loss: 0.7153 - accuracy: 0.6161\n",
      "Test subject:  14\n",
      "Test Loss: 0.715\n",
      "Test Accuracy: 0.616\n",
      "280/280 [==============================] - 0s 750us/step - loss: 1.4272 - accuracy: 0.4186\n",
      "Test subject:  15\n",
      "Test Loss: 1.427\n",
      "Test Accuracy: 0.419\n",
      "278/278 [==============================] - 0s 715us/step - loss: 0.9874 - accuracy: 0.6891\n",
      "Test subject:  16\n",
      "Test Loss: 0.987\n",
      "Test Accuracy: 0.689\n",
      "285/285 [==============================] - 0s 917us/step - loss: 0.6057 - accuracy: 0.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:24:50,417]\u001b[0m Trial 4 finished with value: 0.7390461226304372 and parameters: {'n_units_l0': 9, 'n_units_l1': 8, 'rate': 0.32376242538419026, 'weight_decay': 1.3446369669195761e-07, 'lr': 5.072264962435793e-05, 'batch_size': 118, 'epoch': 5}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.606\n",
      "Test Accuracy: 0.811\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 671us/step - loss: 0.8500 - accuracy: 0.6803\n",
      "Test subject:  2\n",
      "Test Loss: 0.850\n",
      "Test Accuracy: 0.680\n",
      "270/270 [==============================] - 0s 730us/step - loss: 3.9677 - accuracy: 0.5860\n",
      "Test subject:  3\n",
      "Test Loss: 3.968\n",
      "Test Accuracy: 0.586\n",
      "271/271 [==============================] - 0s 720us/step - loss: 0.9415 - accuracy: 0.5299\n",
      "Test subject:  4\n",
      "Test Loss: 0.941\n",
      "Test Accuracy: 0.530\n",
      "278/278 [==============================] - 0s 656us/step - loss: 0.4434 - accuracy: 0.8313\n",
      "Test subject:  5\n",
      "Test Loss: 0.443\n",
      "Test Accuracy: 0.831\n",
      "276/276 [==============================] - 0s 680us/step - loss: 1.7770 - accuracy: 0.7052\n",
      "Test subject:  6\n",
      "Test Loss: 1.777\n",
      "Test Accuracy: 0.705\n",
      "275/275 [==============================] - 0s 722us/step - loss: 0.5786 - accuracy: 0.7589\n",
      "Test subject:  7\n",
      "Test Loss: 0.579\n",
      "Test Accuracy: 0.759\n",
      "277/277 [==============================] - 0s 792us/step - loss: 0.6329 - accuracy: 0.7833\n",
      "Test subject:  8\n",
      "Test Loss: 0.633\n",
      "Test Accuracy: 0.783\n",
      "275/275 [==============================] - 0s 781us/step - loss: 2.9626 - accuracy: 0.7959\n",
      "Test subject:  9\n",
      "Test Loss: 2.963\n",
      "Test Accuracy: 0.796\n",
      "285/285 [==============================] - 0s 742us/step - loss: 0.6008 - accuracy: 0.7875\n",
      "Test subject:  10\n",
      "Test Loss: 0.601\n",
      "Test Accuracy: 0.788\n",
      "279/279 [==============================] - 0s 851us/step - loss: 0.7909 - accuracy: 0.6317\n",
      "Test subject:  11\n",
      "Test Loss: 0.791\n",
      "Test Accuracy: 0.632\n",
      "279/279 [==============================] - 0s 752us/step - loss: 0.5212 - accuracy: 0.8284\n",
      "Test subject:  13\n",
      "Test Loss: 0.521\n",
      "Test Accuracy: 0.828\n",
      "279/279 [==============================] - 0s 770us/step - loss: 1.0772 - accuracy: 0.5275\n",
      "Test subject:  14\n",
      "Test Loss: 1.077\n",
      "Test Accuracy: 0.528\n",
      "280/280 [==============================] - 0s 750us/step - loss: 0.5285 - accuracy: 0.8177\n",
      "Test subject:  15\n",
      "Test Loss: 0.529\n",
      "Test Accuracy: 0.818\n",
      "278/278 [==============================] - 0s 751us/step - loss: 1.1818 - accuracy: 0.6790\n",
      "Test subject:  16\n",
      "Test Loss: 1.182\n",
      "Test Accuracy: 0.679\n",
      "285/285 [==============================] - 0s 732us/step - loss: 1.0050 - accuracy: 0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:32:28,147]\u001b[0m Trial 5 finished with value: 0.697433598836263 and parameters: {'n_units_l0': 9, 'n_units_l1': 4, 'rate': 0.2016850184187539, 'weight_decay': 9.026544000724536e-07, 'lr': 0.004788532764902405, 'batch_size': 49, 'epoch': 15}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 1.005\n",
      "Test Accuracy: 0.519\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 741us/step - loss: 0.5549 - accuracy: 0.7915\n",
      "Test subject:  2\n",
      "Test Loss: 0.555\n",
      "Test Accuracy: 0.791\n",
      "270/270 [==============================] - 0s 740us/step - loss: 1.9253 - accuracy: 0.7326\n",
      "Test subject:  3\n",
      "Test Loss: 1.925\n",
      "Test Accuracy: 0.733\n",
      "271/271 [==============================] - 0s 777us/step - loss: 0.9982 - accuracy: 0.5349\n",
      "Test subject:  4\n",
      "Test Loss: 0.998\n",
      "Test Accuracy: 0.535\n",
      "278/278 [==============================] - 0s 720us/step - loss: 0.7921 - accuracy: 0.6526\n",
      "Test subject:  5\n",
      "Test Loss: 0.792\n",
      "Test Accuracy: 0.653\n",
      "276/276 [==============================] - 0s 714us/step - loss: 1.5180 - accuracy: 0.6569\n",
      "Test subject:  6\n",
      "Test Loss: 1.518\n",
      "Test Accuracy: 0.657\n",
      "275/275 [==============================] - 0s 726us/step - loss: 0.5838 - accuracy: 0.8308\n",
      "Test subject:  7\n",
      "Test Loss: 0.584\n",
      "Test Accuracy: 0.831\n",
      "277/277 [==============================] - 0s 709us/step - loss: 1.2746 - accuracy: 0.7885\n",
      "Test subject:  8\n",
      "Test Loss: 1.275\n",
      "Test Accuracy: 0.788\n",
      "275/275 [==============================] - 0s 758us/step - loss: 0.6970 - accuracy: 0.7657\n",
      "Test subject:  9\n",
      "Test Loss: 0.697\n",
      "Test Accuracy: 0.766\n",
      "285/285 [==============================] - 0s 751us/step - loss: 0.8447 - accuracy: 0.7897\n",
      "Test subject:  10\n",
      "Test Loss: 0.845\n",
      "Test Accuracy: 0.790\n",
      "279/279 [==============================] - 0s 788us/step - loss: 0.5748 - accuracy: 0.9109\n",
      "Test subject:  11\n",
      "Test Loss: 0.575\n",
      "Test Accuracy: 0.911\n",
      "279/279 [==============================] - 0s 721us/step - loss: 0.5203 - accuracy: 0.8284\n",
      "Test subject:  13\n",
      "Test Loss: 0.520\n",
      "Test Accuracy: 0.828\n",
      "279/279 [==============================] - 0s 737us/step - loss: 0.8893 - accuracy: 0.7394\n",
      "Test subject:  14\n",
      "Test Loss: 0.889\n",
      "Test Accuracy: 0.739\n",
      "280/280 [==============================] - 0s 720us/step - loss: 1.2159 - accuracy: 0.8245\n",
      "Test subject:  15\n",
      "Test Loss: 1.216\n",
      "Test Accuracy: 0.824\n",
      "278/278 [==============================] - 0s 736us/step - loss: 1.0023 - accuracy: 0.7020\n",
      "Test subject:  16\n",
      "Test Loss: 1.002\n",
      "Test Accuracy: 0.702\n",
      "285/285 [==============================] - 0s 739us/step - loss: 0.6511 - accuracy: 0.8366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:37:32,741]\u001b[0m Trial 6 finished with value: 0.7589905619621277 and parameters: {'n_units_l0': 8, 'n_units_l1': 5, 'rate': 0.3504782082829059, 'weight_decay': 2.6504917882756348e-08, 'lr': 2.0829837900951707e-05, 'batch_size': 73, 'epoch': 15}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.651\n",
      "Test Accuracy: 0.837\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 725us/step - loss: 1.2261 - accuracy: 0.8058\n",
      "Test subject:  2\n",
      "Test Loss: 1.226\n",
      "Test Accuracy: 0.806\n",
      "270/270 [==============================] - 0s 714us/step - loss: 3.5082 - accuracy: 0.6893\n",
      "Test subject:  3\n",
      "Test Loss: 3.508\n",
      "Test Accuracy: 0.689\n",
      "271/271 [==============================] - 0s 772us/step - loss: 0.5196 - accuracy: 0.8282\n",
      "Test subject:  4\n",
      "Test Loss: 0.520\n",
      "Test Accuracy: 0.828\n",
      "278/278 [==============================] - 0s 724us/step - loss: 0.5547 - accuracy: 0.7528\n",
      "Test subject:  5\n",
      "Test Loss: 0.555\n",
      "Test Accuracy: 0.753\n",
      "276/276 [==============================] - 0s 704us/step - loss: 3.6132 - accuracy: 0.6997\n",
      "Test subject:  6\n",
      "Test Loss: 3.613\n",
      "Test Accuracy: 0.700\n",
      "275/275 [==============================] - 0s 742us/step - loss: 0.6647 - accuracy: 0.7861\n",
      "Test subject:  7\n",
      "Test Loss: 0.665\n",
      "Test Accuracy: 0.786\n",
      "277/277 [==============================] - 0s 739us/step - loss: 1.4556 - accuracy: 0.7108\n",
      "Test subject:  8\n",
      "Test Loss: 1.456\n",
      "Test Accuracy: 0.711\n",
      "275/275 [==============================] - 0s 709us/step - loss: 1.7461 - accuracy: 0.8292\n",
      "Test subject:  9\n",
      "Test Loss: 1.746\n",
      "Test Accuracy: 0.829\n",
      "285/285 [==============================] - 0s 761us/step - loss: 1.2771 - accuracy: 0.7257\n",
      "Test subject:  10\n",
      "Test Loss: 1.277\n",
      "Test Accuracy: 0.726\n",
      "279/279 [==============================] - 0s 732us/step - loss: 1.2646 - accuracy: 0.4641\n",
      "Test subject:  11\n",
      "Test Loss: 1.265\n",
      "Test Accuracy: 0.464\n",
      "279/279 [==============================] - 0s 749us/step - loss: 0.6014 - accuracy: 0.7465\n",
      "Test subject:  13\n",
      "Test Loss: 0.601\n",
      "Test Accuracy: 0.747\n",
      "279/279 [==============================] - 0s 747us/step - loss: 1.2801 - accuracy: 0.5648\n",
      "Test subject:  14\n",
      "Test Loss: 1.280\n",
      "Test Accuracy: 0.565\n",
      "280/280 [==============================] - 0s 729us/step - loss: 0.9829 - accuracy: 0.8089\n",
      "Test subject:  15\n",
      "Test Loss: 0.983\n",
      "Test Accuracy: 0.809\n",
      "278/278 [==============================] - 0s 716us/step - loss: 2.0754 - accuracy: 0.6804\n",
      "Test subject:  16\n",
      "Test Loss: 2.075\n",
      "Test Accuracy: 0.680\n",
      "285/285 [==============================] - 0s 730us/step - loss: 0.8431 - accuracy: 0.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:41:37,449]\u001b[0m Trial 7 finished with value: 0.7143714904785157 and parameters: {'n_units_l0': 9, 'n_units_l1': 7, 'rate': 0.22194093540852697, 'weight_decay': 6.647756234009619e-08, 'lr': 0.001656828385129499, 'batch_size': 73, 'epoch': 11}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.843\n",
      "Test Accuracy: 0.623\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 709us/step - loss: 0.7117 - accuracy: 0.9395\n",
      "Test subject:  2\n",
      "Test Loss: 0.712\n",
      "Test Accuracy: 0.940\n",
      "270/270 [==============================] - 0s 755us/step - loss: 1.3924 - accuracy: 0.7383\n",
      "Test subject:  3\n",
      "Test Loss: 1.392\n",
      "Test Accuracy: 0.738\n",
      "271/271 [==============================] - 0s 770us/step - loss: 0.5327 - accuracy: 0.8282\n",
      "Test subject:  4\n",
      "Test Loss: 0.533\n",
      "Test Accuracy: 0.828\n",
      "278/278 [==============================] - 0s 705us/step - loss: 0.6136 - accuracy: 0.7382\n",
      "Test subject:  5\n",
      "Test Loss: 0.614\n",
      "Test Accuracy: 0.738\n",
      "276/276 [==============================] - 0s 721us/step - loss: 1.2769 - accuracy: 0.6761\n",
      "Test subject:  6\n",
      "Test Loss: 1.277\n",
      "Test Accuracy: 0.676\n",
      "275/275 [==============================] - 0s 758us/step - loss: 0.6719 - accuracy: 0.8296\n",
      "Test subject:  7\n",
      "Test Loss: 0.672\n",
      "Test Accuracy: 0.830\n",
      "277/277 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.8047\n",
      "Test subject:  8\n",
      "Test Loss: 0.558\n",
      "Test Accuracy: 0.805\n",
      "275/275 [==============================] - 0s 707us/step - loss: 0.9920 - accuracy: 0.7637\n",
      "Test subject:  9\n",
      "Test Loss: 0.992\n",
      "Test Accuracy: 0.764\n",
      "285/285 [==============================] - 0s 725us/step - loss: 0.8106 - accuracy: 0.7807\n",
      "Test subject:  10\n",
      "Test Loss: 0.811\n",
      "Test Accuracy: 0.781\n",
      "279/279 [==============================] - 0s 720us/step - loss: 2.6608 - accuracy: 0.5901\n",
      "Test subject:  11\n",
      "Test Loss: 2.661\n",
      "Test Accuracy: 0.590\n",
      "279/279 [==============================] - 0s 732us/step - loss: 0.6328 - accuracy: 0.7198\n",
      "Test subject:  13\n",
      "Test Loss: 0.633\n",
      "Test Accuracy: 0.720\n",
      "279/279 [==============================] - 0s 731us/step - loss: 0.9395 - accuracy: 0.5053\n",
      "Test subject:  14\n",
      "Test Loss: 0.940\n",
      "Test Accuracy: 0.505\n",
      "280/280 [==============================] - 0s 730us/step - loss: 1.0654 - accuracy: 0.6836\n",
      "Test subject:  15\n",
      "Test Loss: 1.065\n",
      "Test Accuracy: 0.684\n",
      "278/278 [==============================] - 0s 727us/step - loss: 1.3362 - accuracy: 0.6708\n",
      "Test subject:  16\n",
      "Test Loss: 1.336\n",
      "Test Accuracy: 0.671\n",
      "285/285 [==============================] - 0s 706us/step - loss: 0.6375 - accuracy: 0.7587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:45:18,793]\u001b[0m Trial 8 finished with value: 0.7351383169492086 and parameters: {'n_units_l0': 8, 'n_units_l1': 5, 'rate': 0.2682417028161105, 'weight_decay': 4.3000599140414746e-08, 'lr': 3.0464919629671597e-05, 'batch_size': 94, 'epoch': 13}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 0.637\n",
      "Test Accuracy: 0.759\n",
      "len(test_metrics) : 15\n",
      "266/266 [==============================] - 0s 779us/step - loss: 0.6935 - accuracy: 0.8965\n",
      "Test subject:  2\n",
      "Test Loss: 0.694\n",
      "Test Accuracy: 0.897\n",
      "270/270 [==============================] - 0s 786us/step - loss: 1.3045 - accuracy: 0.6619\n",
      "Test subject:  3\n",
      "Test Loss: 1.304\n",
      "Test Accuracy: 0.662\n",
      "271/271 [==============================] - 0s 831us/step - loss: 0.5122 - accuracy: 0.8072\n",
      "Test subject:  4\n",
      "Test Loss: 0.512\n",
      "Test Accuracy: 0.807\n",
      "278/278 [==============================] - 0s 864us/step - loss: 1.3481 - accuracy: 0.6872\n",
      "Test subject:  5\n",
      "Test Loss: 1.348\n",
      "Test Accuracy: 0.687\n",
      "276/276 [==============================] - 0s 791us/step - loss: 1.9401 - accuracy: 0.6501\n",
      "Test subject:  6\n",
      "Test Loss: 1.940\n",
      "Test Accuracy: 0.650\n",
      "275/275 [==============================] - 0s 786us/step - loss: 0.5520 - accuracy: 0.8308\n",
      "Test subject:  7\n",
      "Test Loss: 0.552\n",
      "Test Accuracy: 0.831\n",
      "277/277 [==============================] - 0s 713us/step - loss: 0.5433 - accuracy: 0.8325\n",
      "Test subject:  8\n",
      "Test Loss: 0.543\n",
      "Test Accuracy: 0.833\n",
      "275/275 [==============================] - 0s 742us/step - loss: 2.1182 - accuracy: 0.7879\n",
      "Test subject:  9\n",
      "Test Loss: 2.118\n",
      "Test Accuracy: 0.788\n",
      "285/285 [==============================] - 0s 733us/step - loss: 0.5703 - accuracy: 0.7896\n",
      "Test subject:  10\n",
      "Test Loss: 0.570\n",
      "Test Accuracy: 0.790\n",
      "279/279 [==============================] - 0s 711us/step - loss: 0.8304 - accuracy: 0.7094\n",
      "Test subject:  11\n",
      "Test Loss: 0.830\n",
      "Test Accuracy: 0.709\n",
      "279/279 [==============================] - 0s 719us/step - loss: 0.8490 - accuracy: 0.6452\n",
      "Test subject:  13\n",
      "Test Loss: 0.849\n",
      "Test Accuracy: 0.645\n",
      "279/279 [==============================] - 0s 711us/step - loss: 0.9971 - accuracy: 0.5483\n",
      "Test subject:  14\n",
      "Test Loss: 0.997\n",
      "Test Accuracy: 0.548\n",
      "280/280 [==============================] - 0s 740us/step - loss: 0.5692 - accuracy: 0.8138\n",
      "Test subject:  15\n",
      "Test Loss: 0.569\n",
      "Test Accuracy: 0.814\n",
      "278/278 [==============================] - 0s 716us/step - loss: 1.7316 - accuracy: 0.6853\n",
      "Test subject:  16\n",
      "Test Loss: 1.732\n",
      "Test Accuracy: 0.685\n",
      "285/285 [==============================] - 0s 745us/step - loss: 7.5637 - accuracy: 0.5222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-13 15:49:25,906]\u001b[0m Trial 9 finished with value: 0.7245206594467163 and parameters: {'n_units_l0': 9, 'n_units_l1': 5, 'rate': 0.37735926046117785, 'weight_decay': 4.77594266480736e-06, 'lr': 0.00012714869569853952, 'batch_size': 78, 'epoch': 12}. Best is trial 3 with value: 0.7658190627892812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subject:  17\n",
      "Test Loss: 7.564\n",
      "Test Accuracy: 0.522\n",
      "len(test_metrics) : 15\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7388005753358206"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97312587, 0.67235178, 0.82817554, 0.82205683, 0.72638512,\n",
       "       0.83075523, 0.77704841, 0.81144744, 0.79084319, 0.83903915,\n",
       "       0.7218104 , 0.46127078, 0.80799371, 0.5972535 , 0.42245167])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 5\n",
      "Best trial:\n",
      "  Value: 0.7413948814074198\n",
      "  Params: \n",
      "    n_units_l0: 10\n",
      "    n_units_l1: 6\n",
      "    rate: 0.36825153281114464\n",
      "    weight_decay: 9.117076288736861e-06\n",
      "    lr: 0.008638688848650435\n",
      "    batch_size: 56\n",
      "    epoch: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_hidden1, num_hidden2, drop_rate, weight_decay, lr, b, ep):   \n",
    "    # leave one out method\n",
    "    test_metrics = []\n",
    "        \n",
    "    for sid in ids:\n",
    "        df_train = df[df[\"sid\"] != sid]\n",
    "        df_test = df[df[\"sid\"] == sid]\n",
    "        x_scaled_train = StandardScaler().fit_transform(df_train[feat_list])\n",
    "        x_scaled_test = StandardScaler().fit_transform(df_test[feat_list])\n",
    "        x_train = x_scaled_train\n",
    "        x_test = x_scaled_test\n",
    "        y_train = df_train[\"label\"].values.astype(int)\n",
    "        y_test = df_test[\"label\"].values.astype(int)\n",
    "        K = len(df_train[\"label\"].unique())\n",
    "        y_train1 = one_hot_enc(y_train, K)\n",
    "        y_test1 = one_hot_enc(y_test, K)\n",
    "        n_input_dim = x_train.shape[1]\n",
    "        \n",
    "\n",
    "        model = ANN_model(n_input_dim, K, num_hidden1, num_hidden2, drop_rate, weight_decay)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(lr==lr), metrics=['accuracy'])\n",
    "        hist = model.fit(x_train, y_train1, epochs=ep, batch_size=b, verbose=False)\n",
    "\n",
    "\n",
    "        results = model.evaluate(x_test, y_test1)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "        #acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(\"Test subject: \", sid)\n",
    "        #print(\"Test Loss: %.3f\\nTest Accuracy: %.3f\" %(results[0], results[1]))\n",
    "        print(\"Test accuracy: %.3f\\nTest f1-score: %.3f\" %(results[1],  f1))\n",
    "        test_metrics.append([sid, results[1], f1])\n",
    "        \n",
    "    l = np.array(test_metrics)\n",
    "    #score = l[:,1].mean()\n",
    "    \n",
    "    print(\"len(test_metrics) :\", len(test_metrics))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN_model(8, 3, 8, 8, 0.3, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 715us/step - loss: 0.4656 - accuracy: 0.8020\n",
      "Test subject:  2\n",
      "Test accuracy: 0.802\n",
      "Test f1-score: 0.729\n",
      "270/270 [==============================] - 0s 735us/step - loss: 6.6303 - accuracy: 0.6995\n",
      "Test subject:  3\n",
      "Test accuracy: 0.700\n",
      "Test f1-score: 0.634\n",
      "271/271 [==============================] - 0s 790us/step - loss: 0.4912 - accuracy: 0.8173\n",
      "Test subject:  4\n",
      "Test accuracy: 0.817\n",
      "Test f1-score: 0.745\n",
      "278/278 [==============================] - 0s 767us/step - loss: 0.4909 - accuracy: 0.7422\n",
      "Test subject:  5\n",
      "Test accuracy: 0.742\n",
      "Test f1-score: 0.678\n",
      "276/276 [==============================] - 0s 733us/step - loss: 0.7826 - accuracy: 0.6299\n",
      "Test subject:  6\n",
      "Test accuracy: 0.630\n",
      "Test f1-score: 0.582\n",
      "275/275 [==============================] - 0s 688us/step - loss: 1.7643 - accuracy: 0.7507\n",
      "Test subject:  7\n",
      "Test accuracy: 0.751\n",
      "Test f1-score: 0.680\n",
      "277/277 [==============================] - 0s 762us/step - loss: 0.8659 - accuracy: 0.8128\n",
      "Test subject:  8\n",
      "Test accuracy: 0.813\n",
      "Test f1-score: 0.741\n",
      "275/275 [==============================] - 0s 808us/step - loss: 0.8601 - accuracy: 0.7394\n",
      "Test subject:  9\n",
      "Test accuracy: 0.739\n",
      "Test f1-score: 0.691\n",
      "285/285 [==============================] - 0s 695us/step - loss: 0.5885 - accuracy: 0.7771\n",
      "Test subject:  10\n",
      "Test accuracy: 0.777\n",
      "Test f1-score: 0.712\n",
      "279/279 [==============================] - 0s 735us/step - loss: 1.8078 - accuracy: 0.7003\n",
      "Test subject:  11\n",
      "Test accuracy: 0.700\n",
      "Test f1-score: 0.637\n",
      "279/279 [==============================] - 0s 721us/step - loss: 0.5958 - accuracy: 0.6758\n",
      "Test subject:  13\n",
      "Test accuracy: 0.676\n",
      "Test f1-score: 0.610\n",
      "279/279 [==============================] - 0s 703us/step - loss: 1.7160 - accuracy: 0.3774\n",
      "Test subject:  14\n",
      "Test accuracy: 0.377\n",
      "Test f1-score: 0.332\n",
      "280/280 [==============================] - 0s 704us/step - loss: 0.7726 - accuracy: 0.5749\n",
      "Test subject:  15\n",
      "Test accuracy: 0.575\n",
      "Test f1-score: 0.459\n",
      "278/278 [==============================] - 0s 756us/step - loss: 1.1773 - accuracy: 0.5321\n",
      "Test subject:  16\n",
      "Test accuracy: 0.532\n",
      "Test f1-score: 0.370\n",
      "285/285 [==============================] - 0s 737us/step - loss: 3.8464 - accuracy: 0.4775\n",
      "Test subject:  17\n",
      "Test accuracy: 0.477\n",
      "Test f1-score: 0.452\n",
      "len(test_metrics) : 15\n"
     ]
    }
   ],
   "source": [
    "s = train_model (8, 8, 0.3, weight_decay=1e-6, lr=0.001, b=92, ep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  0.96817541,  0.96838627],\n",
       "       [ 3.        ,  0.61747301,  0.55827781],\n",
       "       [ 4.        ,  0.82817554,  0.75415292],\n",
       "       [ 5.        ,  0.77695084,  0.74055583],\n",
       "       [ 6.        ,  0.73978204,  0.68710593],\n",
       "       [ 7.        ,  0.83075523,  0.75760498],\n",
       "       [ 8.        ,  0.81846988,  0.74999931],\n",
       "       [ 9.        ,  0.79574418,  0.7313066 ],\n",
       "       [10.        ,  0.59090906,  0.5498241 ],\n",
       "       [11.        ,  0.57829159,  0.50479912],\n",
       "       [13.        ,  0.81615007,  0.7438027 ],\n",
       "       [14.        ,  0.61068702,  0.54932387],\n",
       "       [15.        ,  0.78750563,  0.71947172],\n",
       "       [16.        ,  0.57507879,  0.53397181],\n",
       "       [17.        ,  0.83589631,  0.76562267]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13161700874973795"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(s[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12687838636320647"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(s[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6034107385485773"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6739250500996907"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08078760513947895"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(s[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7096994956334431"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:,0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(s[:,0].astype(int),s[:,2]*100)\n",
    "ax.set_yticks(np.arange(0, 101, 10))\n",
    "ax.set_xticks(s[:,0].astype(int))\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xlabel('subject id')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
